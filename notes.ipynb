{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   May7 \n",
    "### try to implement the SVC based on this website project: https://medium.com/@youness.habach/support-vector-machines-svm-explanation-mini-project-9d4b4962be52\n",
    "\n",
    "learn topics:\n",
    "1. reshape()\n",
    "2. what is StandardScaler and how to use it \n",
    "3. how to get the sd and mean after we use fit_transfer \n",
    "4. for traning and testing dataset, we use fit_transfer and tranfer, since we want the scale and the mean be the same \n",
    "5. learn how to use jpblib to save the scale and mean to a pkl file and then load it later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib \n",
    "\n",
    "\n",
    "# Original dataset\n",
    "data = [[25, 30000],\n",
    "        [40, 60000],\n",
    "        [35, 40000],\n",
    "        [50, 80000]]\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "X = data[:,0]\n",
    "print(X)\n",
    "X = data[:,0].reshape(-1,1)\n",
    "Y = data[:,1].reshape(-1,1)\n",
    "print(X)\n",
    " \n",
    " \n",
    "print(\"before scale\", X)\n",
    "print(\"before scale\", Y)\n",
    "sc = StandardScaler()\n",
    "x_scaleed = sc.fit_transform(X)\n",
    "print (\"sc_mean is: \", sc.mean_)\n",
    "print (\"sc_scale is:\", sc.scale_)\n",
    "joblib.dump(sc,\"scaler.pkl\")\n",
    "print(\"after scale\", x_scaleed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# May 8 \n",
    "### learn how to use CSV from the sklearn.svm \n",
    "\n",
    "learn topic:\n",
    "1. different kernel: \n",
    "    - linear:\n",
    "        - SVC(Kkernel=\"linear\", C=1.0)  --> the C here control how hard is this svm, when the C = infinit, then it is a hard svm \n",
    "    - nonlinear: \n",
    "        - poly (polinamial):\n",
    "            - *degree: can be used to set the degree of the polynomial function \n",
    "        - rbf (radial basis function):\n",
    "            - *gamma: \n",
    "                - smaller: more localized kernel & nearby point will contribute more to the boundary & SVM will be more sensitive to individual - points, lesss smooth \n",
    "                - bigger: more smoothb boundry and a more global influence of the data points\n",
    "        - sigmoid:\n",
    "2. how to fit the model:\n",
    "    - svm_model.fit(train_X, train_y)\n",
    "3. how to draw the boundry lines on the graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "#import the dataser from the scv file \n",
    "\n",
    "dataset = pd.read_csv(\"data/Social_Network_Ads.csv\") \n",
    " \n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:,4].values\n",
    "\n",
    "#use the build in function to seperate the train and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "#pretrain the model datatset\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#creat the support vector machine model \n",
    "soft_linear_svm_model = SVC(kernel=\"rbf\", gamma= 10, C = 1e6) \n",
    "#train the svm model \n",
    "soft_linear_svm_model.fit(X_train, y_train)\n",
    "#make the prediction q\n",
    "y_pred = soft_linear_svm_model.predict(X_test)\n",
    "\n",
    "print(\"size of the y_pred\", X_train.shape)\n",
    "\n",
    "#draw points \n",
    "x_coor = X_train[:,0]\n",
    "Y_coor = X_train[:,1]\n",
    "\n",
    "for (index, value) in enumerate(x_coor):\n",
    "    x_temp = x_coor[index]\n",
    "    y_temp = Y_coor[index]\n",
    "    if y_train[index] == 0:\n",
    "        plt.scatter(x_temp,y_temp, c='red',s=5)\n",
    "    else:\n",
    "        plt.scatter(x_temp,y_temp, c='green',s=5)\n",
    "\n",
    "# Generate a mesh grid of points spanning the range of the features\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Make predictions for each point in the mesh grid\n",
    "Z = soft_linear_svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Reshape the predictions to the shape of the mesh grid\n",
    "Z = Z.reshape(xx.shape)\n",
    "print(Z)\n",
    "cmap_custom = mcolors.ListedColormap(['red', 'green'])\n",
    "plt.contourf(xx, yy, Z, alpha=0.4,cmap = cmap_custom)\n",
    "plt.show()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May 9\n",
    "# how to use the SVR to do the linear regression \n",
    "\n",
    "learn topic:\n",
    "1. the dataset collection, preprocessing is same as the svc\n",
    "2. initialize the model:\n",
    "    - kernel: \n",
    "        - linear\n",
    "        - poly\n",
    "        - rbf:\n",
    "            - gamma: the bigger the gamma, more complex the model will be \n",
    "        - sigmoid\n",
    "\n",
    "        roahmlabMLshare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##linear regression \n",
    "\n",
    "#save way to get the data from the csv file \n",
    "linear_regression_dataset = pd.read_csv(\"data/Position_Salaries.csv\")\n",
    "\n",
    "#get the x and y coordination \n",
    "position_level = linear_regression_dataset.iloc[:,1].values.reshape(-1,1)\n",
    "salary = linear_regression_dataset.iloc[:,2].values.reshape(-1,1) \n",
    "print (position_level.shape)\n",
    "\n",
    "#we should do the preprocess of the dataset, so that they will have the 0 mean and the 1 sd \n",
    "sc_1 = StandardScaler()\n",
    "sc_2 = StandardScaler()\n",
    "position_level = sc_1.fit_transform(position_level)\n",
    "salary = sc_2.fit_transform(salary)\n",
    "\n",
    "# print (\"position_level: \", position_level)\n",
    "# print (\"salary: \", salary)\n",
    "\n",
    "#inital the linear ergression model \n",
    "from sklearn.svm import SVR\n",
    "svl_model = SVR(kernel='rbf',gamma = 0.1)\n",
    "svl_model.fit(position_level,salary)\n",
    "\n",
    "prediction = svl_model.predict(position_level)\n",
    "plt.scatter(position_level,salary,color='red')\n",
    "plt.plot(position_level,prediction, color=\"green\")\n",
    "plt.xlabel(\"position\")\n",
    "plt.ylabel(\"salary\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
