{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# number detection project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist_number_detection.py file \n",
    "- 1. load the train and test dataset \n",
    "- 2. use the torch library to reschedule the dataset into the batch size \n",
    "- 3. initialize the model\n",
    "- 4. define the loss fucntion  \n",
    "- 5. define the optimizer \n",
    "- 6. train the model \n",
    "\n",
    "## model.py \n",
    "- 1. initalize the layers we will use in the model \n",
    "- 2. write the forward pass \n",
    "\n",
    "## test.py\n",
    "- 1. load the model \n",
    "- 2. input the test dataset and then analysis the currectness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision #store the common dataset used in the computer vision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,)) # normalize the image, the numbers are mean and sd\n",
    "])\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.001\n",
    "dataset_dir = \"/home/yuzhen/Desktop/ml_learn/number_detection_project/dataset\"\n",
    "model_save_dir = \"/home/yuzhen/Desktop/ml_learn/number_detection_project/md.pth\"\n",
    "train_dataset = torchvision.datasets.MNIST(dataset_dir, train = True, download= True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader (train_dataset,batch_size = batch_size_train, shuffle= True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(dataset_dir, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size_test,shuffle=True)\n",
    "\n",
    "\n",
    "##push the data to the GPU------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"the device currently use is: \", device)\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "## this part is used to display the shape of the test data and label -----------------\n",
    "# examples = enumerate(test_loader)\n",
    "# batch_idx, (example_data, example_targets) = next (examples)\n",
    "\n",
    "# print(example_data.shape)\n",
    "# print(example_targets.shape)\n",
    "# plt.imshow(example_data[0][0],cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(\"the label of the first data is: \", example_targets[0])\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "##design the model (we will write in the seperate file)\n",
    "\n",
    "# initialize the structure of the model \n",
    "network = model.cnn_model() \n",
    "\n",
    "#move the model to the GPU \n",
    "network.to(device)\n",
    "\n",
    "# initialize the optimizer  \n",
    "# the \"momentum\" here means we will not only concider the current gradient vecrior, but also the accumulated gradient.\n",
    "# advantage of the momentum: \n",
    "#   1. move in the same direction as the previous iteration\n",
    "#   2, faster convergence \n",
    "#   3. less oscillations more smooth \n",
    "optimizer = optim.SGD(params=network.parameters(), lr=learning_rate, momentum=0.9) \n",
    "\n",
    "#define the loss function\n",
    "#since it's a multiclass classification problem and we use the log_softmax() as the return of the moodel \n",
    "#We will use the nll_loss as the loss function, the full name is negative log likelyhood loss. \n",
    "loss = F.nll_loss\n",
    "\n",
    "\n",
    "#training loop \n",
    "\n",
    "def train(epoch):\n",
    "    network.train()# show we are in the trainning mode right now \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #in order to use GPU to calcuate, move the data and target to the GPU:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        #STEP1: reset the optimizer:\n",
    "        optimizer.zero_grad()\n",
    "        #STEP2: calculate the result: \n",
    "        #even if when i define the model i don't consider the batch_size, the pytorch can take care of it automatically \n",
    "        output = network(data)\n",
    "        loss_output = loss(output,target) #calcuate the current loss \n",
    "        #STEP3:backward:\n",
    "        loss_output.backward()\n",
    "        #STEP4:update all the parameters in the model \n",
    "        optimizer.step()\n",
    "\n",
    "        #print out the trainning effect:\n",
    "        epoch_number = epoch\n",
    "        total_data_size =  len(train_loader.dataset)\n",
    "        finished_data_size = batch_idx * len(data)\n",
    "        percentage = (finished_data_size / total_data_size) * 100 \n",
    "        loss_value = loss_output.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"current epoch: {epoch_number} ({finished_data_size} / {total_data_size}) {percentage:.2f}%  loss is: {loss_value:.4f}\")\n",
    " \n",
    " \n",
    "# try to run 3 epoch here: \n",
    "for epoch in range(0,6):\n",
    "    if epoch > 3:\n",
    "        learning_rate *= 0.1\n",
    "    train(epoch)\n",
    "\n",
    "\n",
    "## save the model parameters in the direction so that we can directly use it later \n",
    "torch.save(network.state_dict(), model_save_dir)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py \n",
    "- 1. initalize the layers we will use in the model \n",
    "- 2. write the forward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as py \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "## when we define a model:\n",
    "# 1. create model class \n",
    "#       -> define the structure of the model\n",
    "#       -> define the forward path \n",
    "# 2. define the optimizer \n",
    "#       --> optimizer is used to adjust the parameters in the model \n",
    "# 3. loss function\n",
    "#       --> the optimizer will try to optimize the model in the opposite direction of the loss function\n",
    "\n",
    "class cnn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=3, stride=1, padding=1) # the output is 28*28*10\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=3, stride= 1, padding=1) # the output is 28*28*20\n",
    "        self.drop_out = nn.Dropout2d(p = 0.5)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 20, 1280)\n",
    "        self.fc2 = nn.Linear(1280,10)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def conv_combine(self,x,current_conv,if_use_drop_down):\n",
    "        if if_use_drop_down == False:\n",
    "            x = current_conv(x)\n",
    "            x = self.max_pool(x)\n",
    "            x = self.relu(x)\n",
    "        else: \n",
    "            x = current_conv(x)\n",
    "            x = self.drop_out(x) # randomly zero 50 % of the input tensor \n",
    "            x = self.max_pool(x)\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_combine(x,self.conv1,False)\n",
    "        x = self.conv_combine(x,self.conv2,True)\n",
    "        x = x.view(x.size(0),-1) # the first parameter is the batch size \n",
    "        if self.training == True:\n",
    "            x = self.relu(self.drop_out(self.fc1(x)))\n",
    "        else:    \n",
    "            x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test.py\n",
    "- 1. load the model \n",
    "- 2. input the test dataset and then analysis the currectness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as py\n",
    "import model \n",
    "# from mnist_number_detection import model_save_dir, test_loader\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "dataset_dir = \"/home/yuzhen/Desktop/ml_learn/number_detection_project/dataset\"\n",
    "model_save_dir = \"/home/yuzhen/Desktop/ml_learn/number_detection_project/md.pth\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,)) # normalize the image, the numbers are mean and sd\n",
    "])\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(dataset_dir, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size_test,shuffle=True)\n",
    "\n",
    "## initialize the model from the model file \n",
    "network = model.cnn_model()\n",
    "## feed in the parameters to the model from the pth file \n",
    "network.load_state_dict(torch.load(model_save_dir))\n",
    "network.eval()\n",
    "\n",
    "correct_prediction = 0\n",
    "wrong_prediction = 0\n",
    "print(\"the size of the test_dataset is: \", len(test_loader.dataset))\n",
    "for batch_index, (data,target) in enumerate(test_loader):\n",
    "    for single_data, single_target in zip(data,target):\n",
    "        \n",
    "        img = single_data\n",
    "        img = img.unsqueeze(0)\n",
    "        result = network(img)\n",
    "        pred = int(torch.argmax(result).item())\n",
    "        # print(\"the ground truth is: \",single_target)\n",
    "        # print(\"the prediction is: \", pred)\n",
    "        if single_target.item() == pred:\n",
    "            correct_prediction+=1\n",
    "        else:\n",
    "            wrong_prediction+=1\n",
    "\n",
    "\n",
    "total_prediction = correct_prediction + wrong_prediction\n",
    "percentage = (correct_prediction / total_prediction) * 100\n",
    "print(\"the correct_prediction num is:\", correct_prediction)\n",
    "print(\"the wrong_prediction num is: \", wrong_prediction)\n",
    "print(\"the total_prediction num is: \", total_prediction)\n",
    "print(f\"the correct rate is: {percentage:.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_self_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
